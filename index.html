<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Achraf Ben-Hamadou</title>

    <meta name="author" content="Achraf Ben-Hamadou">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Achraf Ben-Hamadou
                </p>
                <p align="justify"> <strong>Short Bio: </strong>
                  Hi everyone, I'm currently an Assistant Professor at the  <a href="https://crns.rnrt.tn">Digital Research Center of Sfax</a> (CRNS) in Tunisia, where I lead a small team "<a href=https://crns-smartvision.github.io">SmartVision</a>" that mostly works on computer vision and deep learning projects. Previously, I earned my PhD (2011) in computer science from the <a href="https://www.lorraine-inp.fr/">INPL</a> (France),
                  and earlier in 2007, I obtained my master's degree from the <a href="https://www.insa-rouen.fr/">INSA Rouen</a> (France). From 2011 to 2012 I was a postdoctoral researcher at the <a href="https://imagine-lab.enpc.fr/"> Imagine Lab ENPC </a>. I have also spent 4 years working for the Driving Assistance Research Center of Valeo as a computer vision researcher in an international industrial environment.
                </p>
                <br>
                <p align="justify">  <strong>Internships: </strong>I am always happy to host and mentor motivated MSc students at the CRNS. If you would like to work with me, please send me an email describing your past experience and current research interests.
                  Make sure to include your CV and a paragraph about specific topics you would like to explore during your internship.</p>

                <p style="text-align:center">
                  <a href="mailto:achraf.benhamadou@crns.rnrt.tn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.fr/citations?user=noMvvYgAAAAJ&hl=en" target=”_blank”>Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/abenhamadou/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Photography_Achraf_Ben_Hamadou.JPG"><img style="width:80%;max-width:80%;object-fit: cover; border-radius: 60%;" alt="profile photo" src="images/Photography_Achraf_Ben_Hamadou.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Some news</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected papers</h2>
              </td>
            </tr>
          </tbody></table>

<table style="width:100%; border-spacing: 0 10px; border-collapse:separate;margin-right:auto;margin-left:auto;">

    <tbody>
        <tr>
              <td class="paper_thumbnail_cell">
                    <div class="line"><img src='images/medshapenet.png' width=100%></div>
              </td>
              <td class="paper_description_cell">
                <a href="https://medshapenet.ikim.nrw/" target="_blank">
                  <span class="papertitle">MedShapeNet--A large-scale dataset of 3D medical shapes for computer vision</span>
                </a>
                <br>
                  Jianning Li <em>et al.</em>
                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="https://medshapenet.ikim.nrw/"><img title = "Go to project home page" src="images/home.png" style="width:18pt; vertical-align: middle"></a>
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->

                <a href="https://arxiv.org/pdf/2308.16139"><img src="images/pdf.png" title = "Download PDF"  style="width:18pt; vertical-align: middle"></a>
                <a href="https://github.com/GLARKI/MedShapeNet2.0" target="_blank"><img src="images/github_pad.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <p> MedShapeNet contains over 100,000 medical shapes, including bones, organs, vessels, muscles, etc., as well as surgical instruments. Its goal is to promote the translation of methods developed in the context of CG/CV to clinical applications. </p>
              </td>
        </tr>

<tr style="padding: 0; margin: 0;">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/lrwar.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <a href="https://crns-smartvision.github.io/lrwar/" target="_blank">
                  <span class="papertitle">LRW-AR: Cross-Attention Fusion of Visual and Geometric Features for Large Vocabulary Arabic Lipreading</span>
                </a>
                <br>
                Samar Daou,<strong> Achraf Ben-Hamadou</strong>,
                <a href="https://rekikamed.github.io">Ahmed Rekik</a>, Abdelaziz Kallel,
                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="https://crns-smartvision.github.io/lrwar/" target="_blank"><img title = "Go to project home page"  src="images/home.png" style="width:18pt; vertical-align: middle"></a>
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->

                <a href="https://arxiv.org/abs/2402.11520"><img src="images/pdf.png" title = "Download PDF" style="width:18pt; vertical-align: middle"></a>
                <a href="https://osf.io/rz49x"><img src="images/dataset.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <p> Arabic lipreading dataset and appraoch leveraging youtube videos and cross-attention fusion of visual and geometric features. </p>
              </td>
</tr>
<tr style="padding: 0px; margin: 0;">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/ieeeaccess2024.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">Leveraging statistical shape priors in gan-based ECG synthesis</span>
                <!-- /a -->
                <br>
                Nour Neifar, <strong> Achraf Ben-Hamadou</strong>, Afef Mdhaffar, Mohamed Jmaiel, Bernd Freisleben
                <br>
                <em>IEEE Access</em>, 2024
                <br>
                <!-- a href="https://crns-smartvision.github.io/lrwar/">project page</--a> -->
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10459195"><img title = "Download PDF"  src="images/pdf.png" style="width:18pt; vertical-align: middle"></a>
                <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
              </td>
</tr>
<tr style =" padding-top:0px">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <div class="line" id='optimEndoscopy'>
                      <video  width=100% muted autoplay loop>
                  <source src="images/matching_demo.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                </div>
              </td>
              <td class="paper_description_cell">
                  <span class="papertitle">Self-supervised endoscopic image key-points matching</span>
                <br>
                Manel Farhat, Houda Chaabouni,<strong> Achraf Ben-Hamadou</strong>
                <br>
                <em>Elsevier  Expert Systems with Applications, Volume 213, 118696</em>, 2023
                <br>
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <div style="display: inline-block;">
                    <a href="https://arxiv.org/pdf/2208.11424" target = "_blank"><img title = "Download PDF"  src="images/pdf.png" style="width:18pt; vertical-align: middle"></a>
                    <a href="https://github.com/abenhamadou/Self-Supervised-Endoscopic-Image-Key-Points-Matching" target="_blank">
                        <img src='images/github_pad.png' style="width:18pt; vertical-align: middle"></a>
                </div>
                    <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
              </td>
</tr>


<tr style="padding: 10px; margin-top: 10px ; margin: 0px; border-bottom:1px solid lightgray">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/teeth3DS_samples.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">

                  <span class="papertitle">Teeth3DS: a benchmark for teeth segmentation and labeling from intra-oral 3D scans</span>
                <br>
                <strong> Achraf Ben-Hamadou</strong>, Oussama Smaoui, Houda Chaabouni, <a href="https://rekikamed.github.io">Ahmed Rekik</a>, Sergi Pujades, Edmond Boyer, Julien Strippoli, Aurelien Thollot, Hugo Setbon, Cyril Trosset, and Edouard Ladroit
                <br>
                <em>arXiv</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2402.11520" target="_blank"><img src="images/pdf.png" title = "Download PDF" style="width:18pt; vertical-align: middle"></a>
                <a href="https://osf.io/rz49x" target="_blank"><img src="images/dataset.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <a href="https://github.com/abenhamadou/3DTeethSeg22_challenge" target="_blank"><img src="images/github_pad.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>

                <p> </p>
              </td>
</tr>



<tr  style="padding: 10px; margin-top: 10px ; margin: 0px; border-bottom:1px solid lightgray">
              <td class="paper_thumbnail_cell">
                <div class="line"><a href="images/eswa2020.png" target="_blank">
                    <img src='images/eswa2020.png' width=100%></a>
                </div>
              </td>
              <td class="paper_description_cell">
                  <span class="papertitle">Learning Local Representations for Scalable RGB-D Face Recognition</span>
                <br>
                Nesrine Grati,
                <strong> Achraf Ben-Hamadou</strong>,
                Mohamed Hammami,
                <br>
                <em>Elsevier  Expert Systems with Applications, Volume 150, 113319</em>, 2020
                <br>
                <!-- a href="https://crns-smartvision.github.io/lrwar/">project page</--a> -->
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <a href="https://www.researchgate.net/publication/339343457_Learning_Local_Representations_for_Scalable_RGB-D_Face_Recognition" target="_blank"><img src="images/pdf.png" title = "Download PDF"  style="width:20pt; vertical-align: middle"></a>
                <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
              </td>
 </tr>

<tr>
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/3Dresearch2016.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">Construction of extended 3D field of views of the internal bladder wall surface: a proof of concept</span>
                <!-- /a -->
                <br>
                <strong> Achraf Ben-Hamadou</strong>, Charles Soussen, and Christian Daul
                <br>
                <em>Springer  3D Research journal, Volume 7, Issue 3</em>, 2016
                <br>
                <!-- a href="https://crns-smartvision.github.io/lrwar/">project page</--a> -->
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <a href="https://arxiv.org/pdf/1607.04773" target="_blank"><img title = "Download PDF"  src="images/pdf.png" style="width:18pt; vertical-align: middle"></a>

                <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
                <p></p>
                <p> </p>
              </td>
  </tr>
  <tr>
              <td class="paper_thumbnail_cell">
                <div class="line">
                    <a href="images/mtap2016.png" target="_blank">
                        <img src='images/mtap2016.png' width=100%> </a>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">An adaptive approach for lip-reading using image and depth data</span>
                <!-- /a -->
                <br>
                <a href="https://rekikamed.github.io">Ahmed Rekik</a>, <strong> Achraf Ben-Hamadou</strong>, and Walid Mahdi

                <br>
                <em>Springer Multimedia Tools and Applications, Volume 75, Issue 14, Pages 8609-8636</em>, 2016
                <br>
                <a href="https://abenhamadou.github.io/miraclvc1/index.html" target="_blank"><img title = "Go to project home page"  src="images/home.png" style="width:18pt; vertical-align: middle"></a>
                <a href="https://www.researchgate.net/publication/279976534_An_adaptive_approach_for_lip-reading_using_image_and_depth_data" target="_blank"><img src="images/pdf.png" style="width:20pt; vertical-align: middle"></a>
                <a href="https://abenhamadou.github.io/miraclvc1/index.html" target="_blank"><img src="images/dataset.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <a href="https://www.youtube.com/watch?v=JjXCL6W5GwU&t=36s" target="_blank"><img src="images/youtube_icon_dark.png" style="width:20pt; vertical-align: middle"></a>
                <p></p>
                <p> </p>
              </td>
  </tr>

<tr>
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/cviu2013.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">Flexible calibration of structured-light systems projecting point patterns</span>
                <!-- /a -->
                <br>
                <strong> Achraf Ben-Hamadou</strong>, Charles Soussen, Christian Daul, Walter Blondel, and Walid Mahdi

                <br>
                <em>Elsevier Computer Vision and Image Understanding, Volume 117, Issue 10, Pages 1468–1481</em>, 2013
                <br>
                <a href="https://abenhamadou.github.io/pdf/Flexible_calibration_of_structured_light.pdf" target = "_blank"><img src="images/pdf.png" style="width:20pt; vertical-align: middle"></a>
                <p></p>
                <p> </p>
              </td>
  </tr>


  </tbody>
</table>

        </td>
      </tr>
    </table>
  </body>
</html>
