<!DOCTYPE HTML>
<html lang="en">
  <head>
          <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q0129ZWTK1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-Q0129ZWTK1');
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Achraf Ben-Hamadou</title>

    <meta name="author" content="Achraf Ben-Hamadou">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Achraf Ben-Hamadou
                </p>
                <p align="justify"> <strong>Short Bio: </strong>
                  Hi everyone, I'm currently an Assistant Professor at the  <a href="https://crns.rnrt.tn">Digital Research Center of Sfax</a> (CRNS) in Tunisia, where I lead a small team <a href="https://crns-smartvision.github.io">SmartVision</a> that mostly works on computer vision and deep learning projects. Previously, I earned my PhD (2011) in computer science from the <a href="https://www.lorraine-inp.fr/">INPL</a> (France),
                  and earlier in 2007, I obtained my master's degree from the <a href="https://www.insa-rouen.fr/">INSA Rouen</a> (France). From 2011 to 2012 I was a postdoctoral researcher at the <a href="https://imagine-lab.enpc.fr/"> Imagine Lab ENPC </a>. I have also spent 4 years working for the Driving Assistance Research Center of Valeo as a computer vision researcher in an international industrial environment.
                </p>
                <br>
                <p align="justify">  <strong>Internships: </strong>I am always happy to host and mentor motivated MSc students at the CRNS. If you would like to work with me, please send me an email describing your past experience and current research interests.
                  Make sure to include your CV and a paragraph about specific topics you would like to explore during your internship.</p>

                <p style="text-align:center">
                  <a href="mailto:achraf.benhamadou@crns.rnrt.tn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.fr/citations?user=noMvvYgAAAAJ&hl=en" target=‚Äù_blank‚Äù>Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/abenhamadou/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Photography_Achraf_Ben_Hamadou.JPG"><img style="width:80%;max-width:80%;object-fit: cover; border-radius: 60%;" alt="profile photo" src="images/Photography_Achraf_Ben_Hamadou.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Some news</h2>          
                    <ul>
                      <li><strong>[July 2025]</strong> Our paper <em>IoSR: End-to-End Intraoral Scans Repairing</em> by Manel Farhat et al. has been accepted for publication in <em><a href="https://bmvc2025.bmva.org/"  target="_blank">BMVC 2025</a> conference (ranked A)</em> <a href="" target="_blank">[Preprint and Demo comming soon!]</a></li>
                      <li><strong>[April 2025]</strong> Our paper <em>Deep Generative Models for Physiological Signals: A Systematic Literature Review</em> by Nour Neifar et al. has been accepted in <em><a href="https://www.sciencedirect.com/journal/artificial-intelligence-in-medicine"  target="_blank">Elsevier Artificial Intelligence in Medicine</a> </em> <a href="https://arxiv.org/pdf/2307.06162" target="_blank">[Read a preprint]</a></li>
                      <li><strong>[Feb 2025]</strong> Our international workshop <em>ODIN2025 ‚Äì Oral and Dental Image aNalysis Workshop</em> has been accepted in conjunction with <em>MICCAI 2025!</em>! üéâ <a href="https://odin-workshops.org/2025/" target="_blank">[Learn More]</a></li>
                      <li><strong>[Dec 2024]</strong> Our paper <em>TSegLab: Multi-stage 3D dental scan segmentation and labeling</em> has been accepted in <em>Elsevier Computers in Biology and Medicine</em>.  <a href="https://crns-smartvision.github.io/tseglab" target="_blank"> [check project homepage]</a> </li>
                      <li><strong>[Dec 2024]</strong> Our paper <em>LRW-AR: Cross-Attention Fusion of Visual and Geometric Features for Large Vocabulary Arabic Lipreading</em> by Samar Daou et al. has been accepted in <em>MDPI Technologies</em> <a href="https://www.mdpi.com/2227-7080/13/1/26" target="_blank">[Read the Article]</a></li>
                      <li><strong>[Oct 2024]</strong> Attending <strong>MICCAI 2024</strong> in Marrakesh, Morocco. üåç</li>
                    </ul>
          
                    <!-- Collapsible Section -->
                    <button  class="btn" id="toggleOlderNews" onclick="toggleNews()">Show Older News ‚ñº</button>
                    <ul id="olderNews" style="display: none;">
                      <li><strong>[Oct 2024]</strong> The <strong>3DTeethLan</strong> challenge is officially closed during the <strong>Dental Cluster Satellite Event</strong> at <strong>MICCAI 2024</strong>.</li>
                    </ul>
                </td>
              </tr>
              <script>
                function toggleNews() {
                  var olderNews = document.getElementById("olderNews");
                  var button = document.getElementById("toggleOlderNews");
    
                  if (olderNews.style.display === "none") {
                    olderNews.style.display = "block";
                    button.textContent = "Hide Older News ‚ñ≤";
                  } else {
                    olderNews.style.display = "none";
                    button.textContent = "Show Older News ‚ñº";
                  }
                }
              </script>
            
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected papers</h2>
              </td>
            </tr>
          </tbody></table>

<table style="width:100%; border-spacing: 0 10px; border-collapse:separate;margin-right:auto;margin-left:auto;">

    <tbody>
    
            <tr  style="padding: 0; margin: 0;">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/slr_ecg.jpg' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <span class="papertitle">Deep Generative Models for Physiological Signals: A Systematic Literature Review </span>
                <br>
                Nour Neifar, Afef Mdhaffar, <strong> Achraf Ben-Hamadou</strong>, Mohamed Jmaiel
                <br>
                <em>Elsevier Artificial Intelligence in Medicine, accepted for publication, 2025</em>
                <br>
                  <a href="https://arxiv.org/pdf/2307.06162" target="_blank"><img src="images/pdf.png" style="width:20pt; vertical-align: middle"></a>
                <p></p>
              </td>
        </tr>
    
        <tr  style="padding: 0; margin: 0;">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/cibm2025.jpg' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <a href="https://crns-smartvision.github.io/tseglab" target="_blank">
                  <span class="papertitle">TSegLab: Multi-stage 3D dental scan segmentation and labeling</span>
                </a>
                <br>
                <a href="https://rekikamed.github.io">Ahmed Rekik</a>, <strong>Achraf Ben-Hamadou</strong>, Oussama Smaoui, Firas Bouzguenda, <a href="https://morpheo.inrialpes.fr/people/pujades/">Sergi Pujades</a>, <a href="https://morpheo.inrialpes.fr/people/Boyer/">Edmond Boyer</a>
                <br>
                <em>Elsevier Computers in Biology and Medicine, Volume: 185, February 2025, 109535</em>
                <br>
                  <a href="https://crns-smartvision.github.io/tseglab" target="_blank"><img title = "Go to project home page" src="images/home.png" style="width:18pt; vertical-align: middle"></a>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482524016202" target="_blank"><img src="images/pdf.png" style="width:20pt; vertical-align: middle"></a>
                  <a href="https://osf.io/xctdy" target="_blank"><img src="images/dataset.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <p></p>
              </td>
        </tr>

<tr style="padding: 0; margin: 0;">
              <td class="paper_thumbnail_cell">
                    <div class="line"><img src='images/medshapenet.png' width=100%></div>
              </td>
              <td class="paper_description_cell">
                <a href="https://medshapenet.ikim.nrw/" target="_blank">
                  <span class="papertitle">MedShapeNet--A large-scale dataset of 3D medical shapes for computer vision</span>
                </a>
                <br>
                  Jianning Li <em>et al.</em>
                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="https://medshapenet.ikim.nrw/"><img title = "Go to project home page" src="images/home.png" style="width:18pt; vertical-align: middle"></a>
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->

                <a href="https://arxiv.org/pdf/2308.16139"><img src="images/pdf.png" title = "Download PDF"  style="width:18pt; vertical-align: middle"></a>
                <a href="https://github.com/GLARKI/MedShapeNet2.0" target="_blank"><img src="images/github_pad.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <p> MedShapeNet contains over 100,000 medical shapes, including bones, organs, vessels, muscles, etc., as well as surgical instruments. Its goal is to promote the translation of methods developed in the context of CG/CV to clinical applications. </p>
              </td>
</tr>

<tr style="padding: 0; margin: 0;">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/lrwar.jpg' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <a href="https://crns-smartvision.github.io/lrwar/" target="_blank">
                  <span class="papertitle">LRW-AR: Cross-Attention Fusion of Visual and Geometric Features for Large Vocabulary Arabic Lipreading</span>
                </a>
                <br>
                Samar Daou,<strong> Achraf Ben-Hamadou</strong>,
                <a href="https://rekikamed.github.io">Ahmed Rekik</a>, Abdelaziz Kallel,
                <br>
                <em>MDPI Technologies, volume 13, no. 1:26</em>, 2025
                <br>
                <a href="https://crns-smartvision.github.io/lrwar/" target="_blank"><img title = "Go to project home page"  src="images/home.png" style="width:18pt; vertical-align: middle"></a>
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->

                <a href="https://arxiv.org/abs/2402.11520"><img src="images/pdf.png" title = "Download PDF" style="width:18pt; vertical-align: middle"></a>
                <a href="https://osf.io/rz49x"><img src="images/dataset.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                  <a href="https://github.com/crns-smartvision/lrwar" target="_blank">
                        <img src='images/github_pad.png' style="width:18pt; vertical-align: middle"></a>
                <p> Arabic lipreading dataset and approach leveraging youtube videos and cross-attention fusion of visual and geometric features. </p>
              </td>
</tr>
<tr style="padding: 0px; margin: 0;">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/ieeeaccess2024.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">Leveraging statistical shape priors in gan-based ECG synthesis</span>
                <!-- /a -->
                <br>
                Nour Neifar, <strong> Achraf Ben-Hamadou</strong>, Afef Mdhaffar, Mohamed Jmaiel, Bernd Freisleben
                <br>
                <em>IEEE Access</em>, 2024
                <br>
                <!-- a href="https://crns-smartvision.github.io/lrwar/">project page</--a> -->
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10459195"><img title = "Download PDF"  src="images/pdf.png" style="width:18pt; vertical-align: middle"></a>
                <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
              </td>
</tr>
<tr style =" padding-top:0px">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <div class="line" id='optimEndoscopy'>
                      <video  width=100% muted autoplay loop>
                  <source src="images/matching_demo.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                </div>
              </td>
              <td class="paper_description_cell">
                  <span class="papertitle">Self-supervised endoscopic image key-points matching</span>
                <br>
                Manel Farhat, Houda Chaabouni,<strong> Achraf Ben-Hamadou</strong>
                <br>
                <em>Elsevier  Expert Systems with Applications, Volume 213, 118696</em>, 2023
                <br>
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <div style="display: inline-block;">
                    <a href="https://arxiv.org/pdf/2208.11424" target = "_blank"><img title = "Download PDF"  src="images/pdf.png" style="width:18pt; vertical-align: middle"></a>
                    <a href="https://github.com/abenhamadou/Self-Supervised-Endoscopic-Image-Key-Points-Matching" target="_blank">
                        <img src='images/github_pad.png' style="width:18pt; vertical-align: middle"></a>
                </div>
                    <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
              </td>
</tr>


<tr style="padding: 10px; margin-top: 10px ; margin: 0px; border-bottom:1px solid lightgray">
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/teeth3DS_samples.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">

                  <span class="papertitle">Teeth3DS: a benchmark for teeth segmentation and labeling from intra-oral 3D scans</span>
                <br>
                <strong> Achraf Ben-Hamadou</strong>, Oussama Smaoui, Houda Chaabouni, <a href="https://rekikamed.github.io">Ahmed Rekik</a>, <a href="https://morpheo.inrialpes.fr/people/pujades/">Sergi Pujades</a>, <a href="https://morpheo.inrialpes.fr/people/Boyer/">Edmond Boyer</a>, Julien Strippoli, Aurelien Thollot, Hugo Setbon, Cyril Trosset, and Edouard Ladroit
                <br>
                <em>arXiv</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2402.11520" target="_blank"><img src="images/pdf.png" title = "Download PDF" style="width:18pt; vertical-align: middle"></a>
                <a href="https://osf.io/xctdy/" target="_blank"><img src="images/dataset.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <a href="https://github.com/abenhamadou/3DTeethSeg22_challenge" target="_blank"><img src="images/github_pad.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>

                <p> </p>
              </td>
</tr>



<tr  style="padding: 10px; margin-top: 10px ; margin: 0px; border-bottom:1px solid lightgray">
              <td class="paper_thumbnail_cell">
                <div class="line"><a href="images/eswa2020.png" target="_blank">
                    <img src='images/eswa2020.png' width=100%></a>
                </div>
              </td>
              <td class="paper_description_cell">
                  <span class="papertitle">Learning Local Representations for Scalable RGB-D Face Recognition</span>
                <br>
                Nesrine Grati,
                <strong> Achraf Ben-Hamadou</strong>,
                Mohamed Hammami,
                <br>
                <em>Elsevier  Expert Systems with Applications, Volume 150, 113319</em>, 2020
                <br>
                <!-- a href="https://crns-smartvision.github.io/lrwar/">project page</--a> -->
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <a href="https://www.researchgate.net/publication/339343457_Learning_Local_Representations_for_Scalable_RGB-D_Face_Recognition" target="_blank"><img src="images/pdf.png" title = "Download PDF"  style="width:20pt; vertical-align: middle"></a>
                <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
              </td>
 </tr>

<tr>
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/3Dresearch2016.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">Construction of extended 3D field of views of the internal bladder wall surface: a proof of concept</span>
                <!-- /a -->
                <br>
                <strong> Achraf Ben-Hamadou</strong>, Charles Soussen, and Christian Daul
                <br>
                <em>Springer  3D Research journal, Volume 7, Issue 3</em>, 2016
                <br>
                <!-- a href="https://crns-smartvision.github.io/lrwar/">project page</--a> -->
                <!-- a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a> -->
                <a href="https://arxiv.org/pdf/1607.04773" target="_blank"><img title = "Download PDF"  src="images/pdf.png" style="width:18pt; vertical-align: middle"></a>

                <!-- a href="https://osf.io/rz49x">Dataset</a>  -->
                <p></p>
                <p> </p>
              </td>
  </tr>
  <tr>
              <td class="paper_thumbnail_cell">
                <div class="line">
                    <a href="images/mtap2016.png" target="_blank">
                        <img src='images/mtap2016.png' width=100%> </a>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">An adaptive approach for lip-reading using image and depth data</span>
                <!-- /a -->
                <br>
                <a href="https://rekikamed.github.io">Ahmed Rekik</a>, <strong> Achraf Ben-Hamadou</strong>, and Walid Mahdi

                <br>
                <em>Springer Multimedia Tools and Applications, Volume 75, Issue 14, Pages 8609-8636</em>, 2016
                <br>
                <a href="https://abenhamadou.github.io/miraclvc1/index.html" target="_blank"><img title = "Go to project home page"  src="images/home.png" style="width:18pt; vertical-align: middle"></a>
                <a href="https://www.researchgate.net/publication/279976534_An_adaptive_approach_for_lip-reading_using_image_and_depth_data" target="_blank"><img src="images/pdf.png" style="width:20pt; vertical-align: middle"></a>
                <a href="https://abenhamadou.github.io/miraclvc1/index.html" target="_blank"><img src="images/dataset.png" style="width:18pt; vertical-align: middle" title="Dataset"></a>
                <a href="https://www.youtube.com/watch?v=JjXCL6W5GwU&t=36s" target="_blank"><img src="images/youtube_icon_dark.png" style="width:20pt; vertical-align: middle"></a>
                <p></p>
                <p> </p>
              </td>
  </tr>

<tr>
              <td class="paper_thumbnail_cell">
                <div class="line">
                  <img src='images/cviu2013.png' width=100%>
                </div>
              </td>
              <td class="paper_description_cell">
                <!-- a href="https://crns-smartvision.github.io/lrwar/"> -->
                  <span class="papertitle">Flexible calibration of structured-light systems projecting point patterns</span>
                <!-- /a -->
                <br>
                <strong> Achraf Ben-Hamadou</strong>, Charles Soussen, Christian Daul, Walter Blondel, and Walid Mahdi

                <br>
                <em>Elsevier Computer Vision and Image Understanding, Volume 117, Issue 10, Pages 1468‚Äì1481</em>, 2013
                <br>
                <a href="https://abenhamadou.github.io/pdf/Flexible_calibration_of_structured_light.pdf" target = "_blank"><img src="images/pdf.png" style="width:20pt; vertical-align: middle"></a>
                <p></p>
                <p> </p>
              </td>
  </tr>

  </tbody>
</table>

        </td>
      </tr>
    </table>
  </body>
</html>
